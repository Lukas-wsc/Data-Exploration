{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df = pd.read_csv('../../Data-Preperation/preprocessed_dataset.csv')\n",
    "\n",
    "df['Text'] = df['Text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ohne Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(df['Text'])\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "LightGBMError",
     "evalue": "scikit-learn is required for lightgbm.sklearn. You must install scikit-learn and restart your session to use this module.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBMClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/DHBW/4.Semester/DataExploration/Data-Exploration/venv/lib/python3.12/site-packages/lightgbm/sklearn.py:574\u001b[0m, in \u001b[0;36mLGBMModel.__init__\u001b[0;34m(self, boosting_type, num_leaves, max_depth, learning_rate, n_estimators, subsample_for_bin, objective, class_weight, min_split_gain, min_child_weight, min_child_samples, subsample, subsample_freq, colsample_bytree, reg_alpha, reg_lambda, random_state, n_jobs, importance_type, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Construct a gradient boosting model.\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \n\u001b[1;32m    458\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;124;03mand grad and hess should be returned in the same format.\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SKLEARN_INSTALLED:\n\u001b[0;32m--> 574\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscikit-learn is required for lightgbm.sklearn. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    575\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou must install scikit-learn and restart your session to use this module.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboosting_type \u001b[38;5;241m=\u001b[39m boosting_type\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m objective\n",
      "\u001b[0;31mLightGBMError\u001b[0m: scikit-learn is required for lightgbm.sklearn. You must install scikit-learn and restart your session to use this module."
     ]
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Text</th>\n",
       "      <th>Ground_Truth_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>Just woke up. Having no school is the best feeling ever</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interviews!  ♫ http://blip.fm/~8bmta</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me for details</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! Tupac Amaru Shakur</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity @SpeakingUpH4H</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target  \\\n",
       "0             0   \n",
       "1             0   \n",
       "2             0   \n",
       "3             0   \n",
       "4             0   \n",
       "...         ...   \n",
       "1599995       4   \n",
       "1599996       4   \n",
       "1599997       4   \n",
       "1599998       4   \n",
       "1599999       4   \n",
       "\n",
       "                                                                                                                        Text  \\\n",
       "0        @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D   \n",
       "1            is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!   \n",
       "2                                  @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds   \n",
       "3                                                                            my whole body feels itchy and like its on fire    \n",
       "4            @nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.    \n",
       "...                                                                                                                      ...   \n",
       "1599995                                                             Just woke up. Having no school is the best feeling ever    \n",
       "1599996                                         TheWDB.com - Very cool to hear old Walt interviews!  ♫ http://blip.fm/~8bmta   \n",
       "1599997                                                            Are you ready for your MoJo Makeover? Ask me for details    \n",
       "1599998                                                    Happy 38th Birthday to my boo of alll time!!! Tupac Amaru Shakur    \n",
       "1599999                                                       happy #charitytuesday @theNSPCC @SparksCharity @SpeakingUpH4H    \n",
       "\n",
       "        Ground_Truth_Label  \n",
       "0                 negative  \n",
       "1                 negative  \n",
       "2                 negative  \n",
       "3                 negative  \n",
       "4                 negative  \n",
       "...                    ...  \n",
       "1599995           positive  \n",
       "1599996           positive  \n",
       "1599997           positive  \n",
       "1599998           positive  \n",
       "1599999           positive  \n",
       "\n",
       "[1600000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_text(text):\n",
    "#     text = re.sub(r'[@#]\\w+', ' ', text)  # Entfernen von Hashtags und \n",
    "#     text = re.sub(r'https?://\\S+', ' ', text)  # Entfernen von Links\n",
    "#     text = re.sub(r\"\\b\\w+['’]\\w+\\b\", ' ', text)  # Entfernen von Kontraktionen wie 's, 'm etc. \n",
    "#     words = text.split()  \n",
    "#     words = [word for word in words if word.lower() not in stop_words]  \n",
    "#     return ' '.join(words)\n",
    "# df['Text'] = df['Text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/I569423/Library/CloudStorage/OneDrive-Personal/DHBW/4.Semester/DataExploration/Data-Exploration/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df = pd.read_csv('../../Data-Preperation/preprocessed_dataset.csv')\n",
    "\n",
    "df['Text'] = df['Text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m text \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m----> 2\u001b[0m embeddings_findings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/DHBW/4.Semester/DataExploration/Data-Exploration/venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:512\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m    504\u001b[0m             features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    505\u001b[0m                 (\n\u001b[1;32m    506\u001b[0m                     features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m                 \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    510\u001b[0m             )\n\u001b[0;32m--> 512\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    513\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/DHBW/4.Semester/DataExploration/Data-Exploration/venv/lib/python3.12/site-packages/sentence_transformers/util.py:561\u001b[0m, in \u001b[0;36mbatch_to_device\u001b[0;34m(batch, target_device)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch[key], Tensor):\n\u001b[0;32m--> 561\u001b[0m         batch[key] \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embeddings_findings = model.encode(text, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_findings = np.array(embeddings_findings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
